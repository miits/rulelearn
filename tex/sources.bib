@Article{Napierala2016,

	author="Napierala, Krystyna 
and Stefanowski, Jerzy",

	title="Types of minority class examples and their influence on learning classifiers from imbalanced data",

	journal="Journal of Intelligent Information Systems",
	
year="2016",
	
month="Jun",

	day="01",
	
volume="46",

	number="3",
	
pages="563--597",

	abstract="Many real-world applications reveal difficulties in learning classifiers from imbalanced data. Although several methods for improving classifiers have been introduced, the identification of conditions for the efficient use of the particular method is still an open research problem. It is also worth to study the nature of imbalanced data, characteristics of the minority class distribution and their influence on classification performance. However, current studies on imbalanced data difficulty factors have been mainly done with artificial datasets and their conclusions are not easily applicable to the real-world problems, also because the methods for their identification are not sufficiently developed. In our paper, we capture difficulties of class distribution in real datasets by considering four types of minority class examples: safe, borderline, rare and outliers. First, we confirm their occurrence in real data by exploring multidimensional visualizations of selected datasets. Then, we introduce a method for an identification of these types of examples, which is based on analyzing a class distribution in a local neighbourhood of the considered example. Two ways of modeling this neighbourhood are presented: with k-nearest examples and with kernel functions. Experiments with artificial datasets show that these methods are able to re-discover simulated types of examples. Next contributions of this paper include carrying out a comprehensive experimental study with 26 real world imbalanced datasets, where (1) we identify new data characteristics basing on the analysis of types of minority examples; (2) we demonstrate that considering the results of this analysis allow to differentiate classification performance of popular classifiers and pre-processing methods and to evaluate their areas of competence. Finally, we highlight directions of exploiting the results of our analysis for developing new algorithms for learning classifiers and pre-processing methods.",
	
issn="1573-7675",
	
doi="10.1007/s10844-015-0368-1",
	
url="https://doi.org/10.1007/s10844-015-0368-1"

}


@Article{Wilson1997,

	author="Wilson, D. Randall 
and Martinez, Tony R.",

	title="Improved Heterogeneous Distance Functions",

	journal="Journal of Artificial Intelligence Research",
	
year="1997",
	
month="Jan",

	
volume="6",

	
doi="10.1613/jair.346",
	
url="https://doi.org/10.1613/jair.346"

}


@Article{Frank2001,
author = "Frank, Eibe and Hall, Mark",
year = "2001",
month = "Aug",
pages = "145--156",
title = "A Simple Approach to Ordinal Classification",
volume = "2167",
journal = "Lecture Notes in Computer Science",
doi = "10.1007/3-540-44795-4_13"
}

@article{Blaszczynski2014,
author = {Błaszczyński, Jerzy and Stefanowski, Jerzy},
year = {2014},
month = {10},
pages = {},
title = {Neighbourhood sampling in bagging for imbalanced data},
volume = {150},
journal = {Neurocomputing},
doi = {10.1016/j.neucom.2014.07.064}
}